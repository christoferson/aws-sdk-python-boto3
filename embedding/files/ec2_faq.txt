Q: Amazon Elastic Compute Cloud (Amazon EC2) とは何ですか?

Amazon EC2 は、サイズ変更可能なコンピューティング性能をクラウド内で提供するウェブサービスです。また、ウェブスケールのコンピューティングをデベロッパーが簡単に利用できるよう設計されています。

Q: Amazon EC2 で何ができますか?

Amazon Simple Storage Service (Amazon S3) がクラウド内のストレージを可能とするのとまったく同様に、Amazon EC2 は、クラウド内での「コンピューティング」を可能にします。  Amazon EC2 のシンプルなウェブサービスインターフェイスによって、手間をかけず、必要な機能を取得および設定できます。お客様のコンピューティングリソースに対して、高機能なコントロールが提供され、Amazon の実績あるインフラストラクチャ上で実行できます。Amazon EC2 では、わずか数分間で新規サーバーインスタンスを取得して起動できるようになります。これにより、コンピューティング要件の変化に合わせて、すばやく容量をスケールアップおよびスケールダウンできます。実際に使用した分のみ料金が発生するため、Amazon EC2 はコンピューティングの経済性も変革します。

Q: どうすれば Amazon EC2 の使用を開始できますか?

Amazon EC2 にサインアップするには、Amazon EC2 詳細ページ上の [このウェブサービスにサインアップ] ボタンを選択します。このサービスにアクセスするには、AWS のアカウントを保有している必要があります。これをまだ持っていない場合は、Amazon EC2 サインアッププロセスの開始時に、プロンプト画面が表示されてこれを作成することができます。サインアップの後、Amazon EC2 ドキュメントをご参照ください。ここには開始方法に関するガイドが含まれています。

Q: Amazon EC2 にサインアップする際、自分の電話番号の検証を求められるのはなぜですか?

Amazon EC2 登録には、有効な電話番号と E メールを AWS に提出することが必要です。これはお客様に連絡する必要が生じた場合のためです。電話番号の検証に要するのは数分のみです。登録プロセス中に電話を受信し、電話のキーパッドを使用して PIN 番号を入力してください。

Q: デベロッパーが以前できなかったことで、現在できるようになったことは何ですか?

小規模なデベロッパーには大規模なコンピューティングリソースを獲得する資本がないため、これまで、予期せぬ負荷の急上昇に対応するためのキャパシティーを確保できませんでした。Amazon EC2 は、すべての開発者が初期費用やパフォーマンスの妥協なしに、Amazon 独自の大規模なメリットを活用できるよう支援します。現在デベロッパーは、ビジネスがどれだけの成功を収めたとしても、そのビジネス要件を満たすのに必要なコンピューティング性能については、安価かつ簡単に確保できることを理解しています。

サービスの「柔軟な」特性により、デベロッパーはすぐに規模を拡張してトラフィックや需要の急上昇に対応することができます。必要となるシステムリソースが予期せず変更する (上下する) 場合でも、Amazon EC2 は即時に対応できます。つまりデベロッパーには、その時々で必要となるリソース数をコントロールする能力が与えられます。対照的に、従来のホスティングサービスは一般的に、固定された時間枠で、固定されたリソース数を提供します。つまり、利用量が急速に変化する、予想不能である、または様々な間隔で大きなピークを迎えることが知られている場合でも、ユーザーが簡単に対応できることはごくわずかです。

Q: Amazon EC2 環境でシステムを稼動させるにはどうすればよいですか?

アカウントをセットアップして AMI を選択または作成すると、インスタンスを起動する準備が整います。RunInstances API コールを使用して、任意の数のオンデマンドインスタンス上で AMI を開始できます。起動したいインスタンス数を明示するだけで完了します。 ご使用のオンデマンドのクォータを超えて実行したい場合は、「Amazon EC2 インスタンス申請フォーム」をご提出ください。

Amazon EC2 でリクエストが対応可能な場合、RunInstances で要求されたインスタンスの起動が開始されます。DescribeInstances API コールを使用して、インスタンスのステータスについて確認できます。また、TerminateInstances API 呼び出しを使用して、任意の数のインスタンスをプログラム的に終了することもできます。

Amazon EBS ブートパーティションを使用してインスタンスを実行中の場合は、StopInstances API コールを使用して、コンピュートリソースを解放しつつ、ブートパーティション上でデータを格納することもできます。Amazon EBS ブートパーティションで関連インスタンスの再起動の準備が整ったら、StartInstances API を使用できます。

さらに、お客様のアプリケーション利用時間が調整可能なものであれば、スポットインスタンスを使用して利用コストをさらに削減することもできます。スポットインスタンスの利用方法に、詳細な説明が記載されていますので、ぜひご覧ください。

ご希望であれば、AWS マネジメントコンソール または当社のコマンドラインツールを使用したコマンドラインで、これらすべてのアクションを実行することもできます。これらの機能は、このウェブサービス API に実装されています。

Q: ルートデバイスにローカルインスタンスストアを使用するのと、Amazon Elastic Block Store (Amazon EBS) を使用するのでは、何が違いますか?

Amazon EC2 インスタンスを起動する場合、Amazon EBS またはローカルインスタンスストア上でルートデバイスデータを格納する機能があります。Amazon EBS を使用することにより、ルートデバイス上のデータは、インスタンスの稼動状況とは無関係に永続化します。これによって、インスタンスの停止と再起動を連続して行えます。これはお客様のラップトップをシャットダウンして、それが再度必要になった場合に再起動するのと似ています。

一方、ローカルインスタンスストアは、インスタンスが稼動している間のみ存続します。これはデータがルートデバイスに格納されていない場合に、インスタンスを安価な方法で起動することができます。たとえば、このオプションを使用して、各インスタンスがウェブトラフィックを処理するためのクローンである、大規模なウェブサイトを運営しているお客様がいらっしゃいます。

Q: システムの稼動準備にはどの程度の時間がかかりますか?

一般的には、RunInstances 呼び出しの発行から、リクエストされた全インスタンスで起動シーケンスが開始されるまで、10 分かかりません。この時間は、AMI のサイズ、作成中のインスタンス数、AMI をどれくらい最近に起動したかなど、さまざまな要素に依存します。初めて起動するイメージでは、起動までに多少時間がかかる場合があります。

Q: Amazon EC2 ではシステムの読み込みと保存はどのように実行されますか?

Amazon EC2 では、オペレーティングシステムからアプリケーションに至るまで、インスタンスに関するあらゆることをセットアップして設定することができます。Amazon マシンイメージ (AMI) は、シンプルなパッケージ環境であり、インスタンスをセットアップして起動するのに必要なものはすべて含まれています。AMI は、インスタンスのデプロイのユニットです。1 つの AMI のみを保有することもでき、また複数の AMI (例: ウェブサーバー、アプリケーションサーバー、データベース) をシステムの構成要素として構築してもかまいません。Amazon EC2 はさまざまなツールを提供して、AMI の作成を容易にしています。カスタム AMI を使用した場合は、それをバンドルする必要があります。Amazon EBS でサポートされたルートデバイスにイメージをバンドルしている場合、AWS マネジメントコンソールでバンドルコマンドを簡単に使用することができます。インスタンスストアのブートパーティションでイメージをバンドルしている場合、AMI ツールを使用してそれを Amazon S3 にアップロードする必要があります。Amazon EC2 は Amazon EBS および Amazon S3 を使用して、信頼性の高い、スケーラブルな AMI のストレージを提供して、お客様の依頼があった場合に当社がそれらを起動できるようにします。

または、お客様が望む場合には、お客様自身の AMI を最初からセットアップする必要はありません。世界中で利用可能な数多くの AMI から、自分に役立つ AMI を選択することができます。たとえば、シンプルな Linux サーバーのみが必要な場合、標準の Linux ディストリビューション AMI の 1 つを選択できます。

Q: 自分のシステムにはどのようにアクセスしますか?

アプリケーションスタックの実行を開始する RunInstances 呼び出しは、DNS 名のセットを返します。これは起動中の各システムのために 1 つずつあります。この名前は、これがお客様自身のデータセンターにある場合に、システムに正確にアクセスするために使用することができます。お客様のオペレーティングシステムスタックがこれを実行する間に、このマシンを所有します。

Q: Amazon EC2 を Amazon S3 と連携して使用するのですか?

はい。Amazon EC2 を、ローカルインスタンスストレージにサポートされたルートデバイスと共に、インスタンスのための Amazon S3 と連携して使用します。Amazon S3 を使用することにより、デベロッパーは、Amazon がウェブサイトにおけるそのグローバルネットワークを運用するのに使用しているのと同じ、高い拡張性や信頼性を備えた、迅速で、安価なデータストレージインフラストラクチャにアクセスすることができます。Amazon EC2 環境でシステムを実行するために、デベロッパーは、自身の AMI を Amazon S3 に読み込み、それを Amazon S3 と Amazon EC2 の間で移動するためのツールを使用します。AMI に関する詳細は、Amazon EC2 ではシステムの読み込みと保存はどのように実行されますか をご覧ください。

デベロッパーの方々に、Amazon EC2 および Amazon S3 の組み合わせが非常に便利であると思っていただければ幸いです。Amazon EC2 は、クラウド内で安価で拡張性のある計算処理能力を提供する一方、Amazon S3 を使用すれば、ユーザーがデータを安心して格納することができます。

Q: Amazon EC2 ではいくつのインスタンスを実行できますか?

vCPU ベースのオンデマンドインスタンスの制限ごとにオンデマンドインスタンスを実行すること、20 個のリザーブドインスタンスを購入すること、1 つのリージョンにつき動的スポット制限ごとにスポットインスタンスをリクエストすることという制限があります。新規の AWS アカウントでは、当初この上限よりも少ない数に制限されることがあります。
それを超えるインスタンスを必要とする場合は、お客様のユースケースを含めて「Amazon EC2 上限引き上げ申請フォーム」にご記入ください。上限の引き上げを検討いたします。上限の引き上げは、申請されたリージョンに限定されます。

Q: Amazon EC2 インスタンスから E メールを送信する際に制限はありますか?

はい。E メール送信用の Amazon EC2 アドレスの品質を維持するため、当社は EC2 アカウントから送信できる E メールの量に既定値による制限を実施します。EC2 から大量の E メールを送信したい場合は、このフォームに記入することによって、アカウントからこれらの制限を削除するよう申請できます。

Q: キャパシティーのスケールアップやスケールダウンはどのくらいの時間で実行できますか?

Amazon EC2 は真に柔軟なコンピューティング環境を提供します。Amazon EC2 を使用すれば、数分以内にキャパシティーの増減を行うことができます。数時間あるいは数日かかることはありません。一から数百、または数千のサーバーインスタンスさえ、同時に作動させることができます。インスタンスを増やす必要がある場合は、RunInstance を呼び出すだけです。その後 Amazon EC2 は、一般的には数分以内で、お客様の新しいインスタンスをセットアップします。もちろん、これはすべてウェブサービス API でコントロールされるため、お客様のアプリケーションではそのニーズに応じて、自動的なスケールアップやスケールダウンを行えます。

Q: サポートされるオペレーティングシステム環境はどのようなものですか?

Amazon EC2 では現在、Amazon Linux、Ubuntu、Windows Server、Red Hat Enterprise Linux、SUSE Linux Enterprise Server、openSUSE Leap、Fedora、Fedora CoreOS、Debian、CentOS、Gentoo Linux、Oracle Linux、および FreeBSD といった、さまざまなオペレーティングシステムがサポートされています。その他のプラットフォームにもサポートを拡大するよう検討しています。
Q: Amazon EC2 は ECC メモリを使用しますか？

当社の経験によれば、サーバーインフラストラクチャには ECC メモリが必要であり、Amazon EC2 の基盤となっているすべてのハードウェアが ECC メモリを使用しています。

Q: このサービスは、単純なホスティングサービスとどのように異なりますか?

従来のホスティングサービスは、一般的にはあらかじめ設定されたリソースを、固定された時間枠で、事前に決定された金額で提供するというものでした。Amazon EC2 は、それがデベロッパーに与える柔軟性、コントロール、著しいコスト削減において根本的に異なっています。これは Amazon.com の堅牢なインフラストラクチャの恩恵と共に、Amazon EC2 を彼ら自身のデータセンターのように扱えることを意味にします。

必要となるシステムリソースが予期せず変更する (上下する) 場合でも、Amazon EC2 は即時に対応できます。つまりデベロッパーには、その時々で必要となるリソース数をコントロールする能力が与えられます。対照的に、従来のホスティングサービスは一般的に、固定された時間枠で、固定されたリソース数を提供します。つまり、利用量が急速に変化する、予想不能である、または様々な間隔で大きなピークを迎えることが知られている場合でも、ユーザーが簡単に対応できることはごくわずかです。

第二に、多くのホスティングサービスは、提供するコンピュートリソースに対して、完全なコントロールをユーザーに付与しません。Amazon EC2 を使用すれば、デベロッパーはいつでもインスタンスを開始してシャットダウンできるだけでなく、それらのインスタンスの設定を、彼らのニーズに合うように完全にカスタマイズしていつでも変更することができます。ほとんどのホスティングサービスは類似したシステム要件を有するユーザーグループをより重視しているため、これらの変更に対しては限られた機能しか提供しません。

最後に、Amazon EC2 を使用すれば、デベロッパーは実際のリソース消費に応じた従量課金の恩恵を享受することができます – しかも非常に低料金です。ほとんどのホスティングサービスでは、実際に使用される計算処理能力とは無関係に、ユーザーが事前に固定料金を支払う必要があります。そのため、短時間でリソースの規模をすばやくスケールアップできない欠点を補うため、ユーザーがリソースを購入しすぎるリスクがあります。 

EC2 オンデマンドインスタンス制限
Q: 何が変更されますか?

Amazon EC2 はオンデマンドインスタンス制限を、現在の数量ベースの制限から、新たに vCPU ベースの制限に移行し、AWS のお客様の制限管理エクスペリエンスを簡素化します。vCPU ベースの制限に対する使用量は、アプリケーションのニーズを満たすインスタンスタイプの任意の組み合わせを起動するための Amazon EC2 インスタンスタイプにおける vCPU (仮想中央演算処理装置) の数によって測定されます。

Q: vCPU ベースの制限とはどのようなものですか?

AWS アカウントでの 1 つ以上のオンデマンドインスタンスの実行は制限されています。Amazon EC2 は、 AWS アカウントで実行中のオンデマンドインスタンスに割り当てられた 総 vCPU (仮想中央演算処理装置) 数に基づき、各制限に対する使用量を測定します。次の表は、各インスタンスサイズの vCPU の数を示しています。インスタンスタイプにおける vCPU のマッピングは異なる可能性があります。詳細については、Amazon EC2 のインスタンスタイプを参照してください。
インスタンスサイズ	vCPU
nano	1
micro	1
スモール	1
ミディアム	1
ラージ	2
エクストララージ	4
2xlarge	8
3xlarge	12
4xlarge	16
8xlarge	32
9xlarge	36
10xlarge	40
12xlarge	48
16xlarge	64
18xlarge	72
24xlarge	96
32xlarge	128
Q: Amazon EC2 で実行できるオンデマンドインスタンスの数はどれくらいですか?

5 つの vCPU ベースのインスタンス制限があり、特定のインスタンスファミリーの使用できるキャパシティの量をそれぞれ定義します。ジェネレーション、サイズ、またはバリアント設定 (例: ディスク、プロセッサータイプ) に関係なく、特定のインスタンスファミリーの使用量はすべて、下記の表に記載されているファミリーの総 vCPU 上限に追加されます。新規の AWS アカウントでは、当初この上限よりも少ない数に制限されることがあります。
オンデマンドインスタンス制限名	デフォルトの vCPU 制限
オンデマンド標準 (A, C, D, H, I, M, R, T, Z) インスタンスの実行	1152 個の vCPU
オンデマンド F インスタンスの実行	128 個の vCPU
オンデマンド G インスタンスの実行	128 個の vCPU
オンデマンド Inf インスタンスの実行	128 個の vCPU
オンデマンド P インスタンスの実行	128 個の vCPU
オンデマンド X インスタンスの実行	128 個の vCPU
オンデマンドインスタンスの vCPU ベース制限リージョンはありますか?

はい、AWS アカウントのオンデマンドインスタント制限はリージョンごとに設定されます。

Q: これらの制限は時間経過とともに変わりますか?

はい。制限は時間の経過とともに変わる可能性があります。Amazon EC2 は各リージョン内で使用状況を継続的に監視しており、EC2の使用に基づいて制限が自動的に引き上げられます。

Q: 制限の引き上げをリクエストするにはどうすればよいですか?

EC2 によって使用状況に基づきオンデマンドインスタンス制限は自動的に引き上げられますが、必要に応じて Amazon EC2 コンソールの制限ページ、Service Quotas コンソールの Amazon EC2 サービスページ、または Service Quotas API/CLI から制限引き上げをリクエストできます。
Q: 新しい vCPU 制限は、どのように計算すればよいですか?

Amazon EC2 インスタンスタイプの各 vCPU マッピングをご確認いただくか、簡易 vCPU 計算ツールを使用して AWS アカウントの vCPU 制限要件の合計を計算します。

Q: vCPU制限はリザーブドインスタンスを購入するときか、スポットインスタンスをリクエストするときに適用されますか?

いいえ。vCPU ベース制限はオンデマンドインスタンスおよびスポットインスタンスを実行するときのみ適用されます。

Q: 現在のオンデマンドインスタンス制限を表示するにはどうすればよいですか?
Amazon EC2 コンソールの EC2 サービスの制限ページ、またはService Quotas コンソールや API から現在のオンデマンドインスタンス制限をご確認いただけます。

Q: これにより実行中のインスタンスは影響を受けますか?

いいえ。vCPU ベース制限をオプトインしても実行中のインスタンスには影響ありません。

Q: 引き続き同じ数のインスタンスを作成できますか?

はい。vCPU ベースのインスタンス制限により、数量ベースのインスタンス制限として、少なくとも同じ数のインスタンスを作成できます。

Q: これらの制限に対してインスタンス使用量を表示することはできますか?

Amazon CloudWatch のメトリクス結合により、Service Quotas コンソールの制限に対する EC2 使用率を表示できます。Service Quotas では、CloudWatch も使用でき、アラームを設定することで、制限に近づいていることをお客様に警告できます。加えて、Trusted Advisor と Limit Monitor でインスタンス使用量の追跡と調査を継続できます。

Q: 引き続き DescribeAccountAttributes API を使用できますか?

vCPU 制限では、使用状況を規制するインスタンス制限の合計がなくなりました。したがって、DescribeAccountAttributes API は、最大インスタンス変数を返さなくなります。代わって、Service Quotas の API を使用して EC2 制限に関する情報を取り出せるようになります。Service Quotas API の詳細については AWS ドキュメントを参照してください。

Q: vCPU 制限は月額料金に影響しますか?

いいえ。EC2 の使用量は、引き続き実行している AMI に応じておよび、インスタンスタイプと作成したインスタンスのサイズにより時間単位または秒単位で計算されます。

Q: vCPU 制限はすべてのリージョンで適用されますか?

vCPU ベースのインスタンス制限は、すべての商用 AWS リージョンで適用されます。
EC2 SMTP エンドポイントポリシーに関する変更点
Q: 何が変更されますか?

2020 年 1 月 7 日に、Amazon EC2 は、お客様やその他の受信者をスパムや E メールの悪用から保護するために、ポート 25 経由の E メールトラフィックをデフォルトで制限する変更の導入を開始しました。ポート 25 は、E メール送信用のデフォルトの SMTP ポートとして広く使われています。過去にポート 25 スロットルをリクエストして、削除したことのある AWS アカウントには、今回の変更による影響はありません。

Q: EC2 からポート 25 に E メールを送信する有効なユースケースがあります。今回のポート 25 制限を解除するにはどうすればよいですか?

EC2 からポート 25 (SMTP) に E メールを送信する有効なユースケースがある場合は、これらの制限を緩和するために「E メール送信制限の削除リクエスト」を送信してください。または、別のポートから E メールを送信するか、または Amazon Simple Email Service (Amazon SES) のような既存の認証済み E メールリレーサービスを活用します。

サービスレベルアグリーメント (SLA)
Q: Amazon EC2 サービスレベルアグリーメント (SLA) では何が保証されますか?

SLA では、リージョン内の Amazon EC2 および Amazon EBS の月間稼動率が 99.99% 以上になるよう保証されます。

Q: SLA サービスクレジットの資格を有しているかどうかを知るにはどうすればよいですか?

サービスを実行しているリージョンの月次請求サイクル中における月間稼働率が 99.99% 未満である場合、Amazon EC2 または Amazon EBS (どちらか利用できなかったもの、またはどちらも利用できない場合は両方) の SLA クレジットの付与対象となります。SLA の利用規約に関するすべての詳細、および請求方法の詳細については、Amazon Compute サービスレベルアグリーメントを参照してください。 

インスタンスタイプ
高速コンピューティングインスタンス | バースト可能なインスタンス | コンピューティング最適化インスタンス  | HPC 最適化インスタンス | 汎用インスタンス | High Memory インスタンス | メモリ最適化インスタンス | 旧世代のインスタンス | ストレージ最適化インスタンス

高速コンピューティングインスタンス
Q: 高速コンピューティングインスタンスとは何ですか?

高速コンピューティングインスタンスのカテゴリには、ハードウェアアクセラレーター、またはコプロセッサを使用して、浮動小数点計算やグラフィック処理などの機能を、CPU で実行中のソフトウェアよりも効率的に実行するインスタンスファミリーが含まれます。Amazon EC2 は、汎用コンピューティング向けの GPU コンピューティングインスタンス、グラフィックを多用するアプリケーション向けの GPU グラフィックインスタンス、高度な科学関連ワークロード向けの FPGA プログラム可能ハードウェアコンピューティングインスタンスという 3 つのタイプの高速コンピューティングインスタンスを提供します。

Q: GPU Graphics インスタンスや GPU Compute インスタンスは、どのような場合に使用すべきですか?

GPU インスタンスは、数千のスレッドを使用するワークロードなど、大量の並列処理を行うアプリケーションに最適です。グラフィック処理は、大量の計算が必要な処理の例です。グラフィック処理では、個々のタスクはそれほど大きくありませんが、実行される操作のセットはパイプラインを形成し、個別の操作のレイテンシーより、このパイプラインのスループットの方が重要です。このレベルの並列処理を利用するアプリケーションを構築するには、さまざまなグラフィック API (DirectX、OpenGL) または GPU コンピューティングプログラミングモデル (CUDA、OpenCL) でのプログラム方法を理解することによる、GPU デバイス固有の知識が必要です。

Q: P4d を使用するメリットがあるのは、どんなアプリケーションですか?

お客様が P4d の使用を期待しているアプリケーションとしては、自然言語理解、自律型車両の知覚モデルトレーニング、画像分類、物体検出、レコメンデーションエンジンなどの機械学習 (ML) ワークロードがあります。GPU 性能の向上により、トレーニングにかかる時間が大幅に短縮され、GPU メモリを追加することで、より大きく、より複雑なモデルのトレーニングが可能になります。HPC のお客様は、P4 の向上した処理性能と GPU メモリを使用して、地震分析、創薬、DNA シーケンス、保険リスクモデリングなどを行うことができます。

Q: P4d インスタンスを P3 インスタンスと比較するとどのようになりますか?

P4 インスタンスは、NVIDIA の最新世代の A100 Tensor Core GPU を搭載しており、前世代の V100 と比べて平均 2.5 倍の TFLOP 性能で、2.5 倍のGPUメモリを提供します。P4 インスタンスは、ソケットあたり 24C の Cascade Lake Intel CPU と、ベクトルニューラルネットワーク命令用の追加の命令セットを備えています。P4 インスタンスは、P3dn と比較して、システムメモリの合計が 1.5 倍、ネットワークスループットが 4 倍であり、P3.16xl と比較すると 16 倍になります。もう 1 つの重要な違いは、NVSwitch GPU インターコネクトスループットが P3 で可能なスループットの 2 倍になるため、各 GPU が同じ 600GB/s の双方向スループットとシングルホップレイテンシーで他のすべての GPU と通信できることです。これにより、アプリケーションを開発する際は、複数の GPU とメモリを単一の大きな GPU および統合されたメモリプールと見なすことができます。P4d インスタンスは、EC2 UltraClusters と呼ばれる密結合のハイパースケールクラスターにもデプロイされます。これにより、最も複雑なマルチノード ML トレーニングや HPC アプリケーションの実行も可能になります。

Q: EC2 UltraClusters とは何ですか? どうすればアクセスできますか?

P4d インスタンスは、EC2 UltraCluster と呼ばれるハイパースケールクラスターにデプロイされます。それぞれの EC2 UltraCluster は、4,000 を超える NVIDIA A100 Tensor Core GPU、ペタビット規模のネットワーキング、FSx for Lustre による拡張可能な低レイテンシーストレージで構成されています。それぞれの EC2 UltraCluster が、世界トップクラスのスーパーコンピューターの 1 つということになります。EC2 SuperCluster では、簡単に P4d インスタンスを起動できます。さらに支援が必要な場合は、お問い合わせください。

Q: P3 や P3dn で使用していた AMI は P4 で動作しますか?

P4 AMI には、A100 GPU 用の新しい NVIDIA ドライバーと、新しいバージョンの ENA ドライバーがインストールされている必要があります。P4 インスタンスは Nitro System を搭載しており、NVMe および ENA ドライバーがインストールされた AMI が必要です。また、P4 には、更新された命令セットに対応する新しい Intel Cascade Lake CPU も搭載されているため、データの前処理にこれらの新しい命令セットを使用する ML フレームワークの最新のディストリビューションを使用することをお勧めします。

Q: P3 インスタンスと G3 インスタンスの違いは何ですか?

P3 インスタンスは次世代の EC2 汎用 GPU コンピューティングインスタンスで、最大 8 つの最新世代 NVIDIA Tesla V100 GPU が搭載されています。これらの新しいインスタンスによってパフォーマンスとスケーラビリティが大幅に向上し、多数の新機能が追加されています。それには、機械学習 (ML) や深層学習 (DL) のパフォーマンス最適化のための新しい Streaming Multiprocessor (SM) アーキテクチャ、第二世代 NVIDIA NVLink 高速 GPU インターコネクト、効率向上に高度に調整された HBM2 メモリが含まれます。

G3 インスタンスは NVIDIA Tesla M60 GPU を使用して、DirectX または OpenGL を使用するグラフィックアプリケーション向けのハイパフォーマンスプラットフォームを提供します。NVIDIA Tesla M60 GPU では NVIDIA GRID Virtual Workstation 機能、および H.265 (HEVC) ハードウェアエンコーディングがサポートされています。G3 インスタンス内の M60 GPU では、それぞれ最大解像度 4096x2160 のモニタ 4 台がサポートされ、同時接続ユーザー 1 人が NVIDIA GRID Virtual Workstation を使用できるライセンスが付与されています。G3 インスタンスを利用するアプリケーションとして、3D ビジュアライゼーション、グラフィック集約型リモートワークステーション、3D レンダリング、アプリケーションストリーミング、動画エンコーディング、およびその他のサーバー側グラフィックワークロードなどが考えられます。

Q: NVIDIA Volta GV100 GPU にはどのようなメリットがありますか?

新しい NVIDIA Tesla V100 アクセラレーターには、新しい強力な Volta GV100 GPU が統合されています。GV100 は先行モデル Pascal GP100 GPU の利点を基に構築されているだけでなく、パフォーマンスとスケーラビリティが大幅に向上しており、プログラマビリティを高める多数の新機能が追加されています。これらの利点により、HPC、データセンター、スーパーコンピュータ、深層学習のシステムやアプリケーションが強化されます。